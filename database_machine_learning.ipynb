{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import re\n",
    "data = pd.read_csv('edited_data.csv')\n",
    "X = data['Objectives']+'. '+ data['Description']\n",
    "\n",
    "X = X.str.replace('<ul>', '').str.replace('<li>','').str.replace('</li>','').str.replace('</ul>','').str.replace('\\n','')\n",
    "\n",
    "X = X.fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       contribution metu hs ankara lab protocols coll...\n",
      "1       attend makerfaire hannover demonstrate first p...\n",
      "2       organize biotech day present project large gro...\n",
      "3       contact connect community labs europe visit ig...\n",
      "4       invite technik garage german community lab aac...\n",
      "                              ...                        \n",
      "2148                                                     \n",
      "2149     attended fourth conference china igemer commu...\n",
      "2150     created week long exhibition three igem teams...\n",
      "2151     host architects competition microorganism app...\n",
      "2152     secure funding supplies metagenomic sequencin...\n",
      "Length: 2153, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords \n",
    "#nltk.download('punkt')\n",
    "#nltk.download(\"stopwords\")\n",
    "data = data.reset_index(drop=True)\n",
    "REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|@,;]')\n",
    "BAD_SYMBOLS_RE = re.compile('[^0-9a-z #+_]')\n",
    "stop_words = set(stopwords.words('english')) \n",
    "not_delete = [\"but\", \"shan't\", \"wasn't\", \"couldn't\", \"didn't\", \"hadn't\", \"against\", \"no\", \"haven't\", \"shouldn't\", \"needn't\", \"wouldn't\", \"aren't\", \"mightn't\", \"won't\", \"isn't\", \"hasn't\", \"don't\", \"mustn't\", \"doesn't\", \"not\"]\n",
    "STOPWORDS = [w for w in stop_words if w not in not_delete]\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "        text: a string\n",
    "        \n",
    "        return: modified initial string\n",
    "    \"\"\"\n",
    "    text = text.lower() # lowercase text\n",
    "    text = REPLACE_BY_SPACE_RE.sub(' ', text) # replace REPLACE_BY_SPACE_RE symbols by space in text. substitute the matched string in REPLACE_BY_SPACE_RE with space.\n",
    "    text = BAD_SYMBOLS_RE.sub('', text) # remove symbols which are in BAD_SYMBOLS_RE from text. substitute the matched string in BAD_SYMBOLS_RE with nothing. \n",
    "    text = ' '.join(word for word in text.split() if word not in STOPWORDS) # remove stopwors from text\n",
    "    return text\n",
    "\n",
    "X = X.apply(clean_text)\n",
    "X = X.str.replace('\\d+', '')\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "porter = PorterStemmer()\n",
    "def stemSentence(sentence):\n",
    "    token_words=word_tokenize(sentence)\n",
    "    stem_sentence=[]\n",
    "    for word in token_words:\n",
    "        stem_sentence.append(porter.stem(word))\n",
    "        stem_sentence.append(\" \")\n",
    "    return \"\".join(stem_sentence)\n",
    "\n",
    "for i in range(0,X.count()):\n",
    "    X[i] = stemSentence(X[i])\n",
    "\n",
    "for a in X:\n",
    "    a = ' '.join(a.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#multilabel classifier: project tag 0.9519213258058642\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from scipy import stats\n",
    "\n",
    "y2 = data['Project Tag']\n",
    "mlb = MultiLabelBinarizer()\n",
    "y2 = y2.fillna(\"N/A\")\n",
    "y2 = y2.str.split(', ')\n",
    "\n",
    "for i in range(0, len(y2)):\n",
    "    for j in range(0, len(y2[i])):\n",
    "        y2[i][j] = y2[i][j].replace(\"Community Event \", \"Community Event\")\\\n",
    "        .replace(\"Conference/Panel Discussion \", \"Conference/Panel Discussion\")\\\n",
    "        .replace(\"Educational Material \", \"Educational Material\")\\\n",
    "        .replace(\"Social Media \", \"Social Media\").replace(\"Survey \", \"Survey\")\\\n",
    "        .replace(\"Teaching Activity \", \"Teaching Activity\")\n",
    "    \n",
    "mlb_y2 = mlb.fit_transform(y2)\n",
    "\n",
    "#print(mlb.classes_)\n",
    "\n",
    "#from sklearn.model_selection import train_test_split\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, mlb_y2, test_size=0.3, random_state=52)\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.multioutput import ClassifierChain\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "'''\n",
    "#Bag of Words\n",
    "OneVsRest_classifier = Pipeline([\n",
    "('vectorizer', CountVectorizer(ngram_range=(1, 2),strip_accents = 'unicode')),\n",
    "('tfidf', TfidfTransformer(sublinear_tf=True)),\n",
    "('clf', OneVsRestClassifier(SVC(C=1.0, kernel='linear')))])\n",
    "\n",
    "OneVsRest_classifier.fit(X_train, y_train) \n",
    "predicted = OneVsRest_classifier.predict(X_test)\n",
    "\n",
    "\n",
    "#exact match\n",
    "print(OneVsRest_classifier.score(X_test, y_test))\n",
    "\n",
    "#simple match\n",
    "print('OneVsRestClassifier_test:'+ str(np.mean(predicted == y_test)))\n",
    "'''\n",
    "\n",
    "Tfidf_vect = TfidfVectorizer(ngram_range=(1, 2), strip_accents = 'unicode')\n",
    "#X_train = Tfidf_vect.fit_transform(X_train)\n",
    "#X_test = Tfidf_vect.transform(X_test)\n",
    "X_tran = Tfidf_vect.fit_transform(X)\n",
    "\n",
    "# Fit an ensemble of SVM classifier chains and take the average prediction of all the chains.\n",
    "from sklearn.metrics import jaccard_score\n",
    "chains2 = [ClassifierChain(SVC(C=1.0, kernel='linear'), order='random', random_state=i)\n",
    "          for i in range(10)]\n",
    "for chain in chains2:\n",
    "    #chain.fit(X_train, y_train)\n",
    "    chain.fit(X_tran, mlb_y2)\n",
    "    \n",
    "#Y_pred_chains = np.array([chain.predict(X_test) for chain in chains2])\n",
    "\n",
    "\n",
    "#0项是mode，1项是count\n",
    "#y_pred = stats.mode(Y_pred_chains)[0]\n",
    "\n",
    "\n",
    "#simple match\n",
    "#print('Chain_Classifier_test:'+ str(np.mean(y_pred == y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#OneVsRest_classifier.fit(X, mlb_y2)\n",
    "new_data = pd.read_csv('bert_summary_full.csv')\n",
    "X_new = new_data['original']\n",
    "#X_new = new_data['summarized']\n",
    "X_new = X_new.str.replace('\\n', '').str.replace('\\t','')\n",
    "X_new = X_new.fillna('')\n",
    "\n",
    "X_clean = X_new.apply(clean_text)\n",
    "X_clean = X_clean.str.replace('\\d+', '')\n",
    "\n",
    "for i in range(X_clean.count()):\n",
    "    X_clean[i] = stemSentence(X_clean[i])\n",
    "    \n",
    "#如果两个词中间有许多空格，删掉，换成一个空格\n",
    "for X in X_clean:\n",
    "    X = ' '.join(X.split())\n",
    "    \n",
    "X_new_tran = Tfidf_vect.transform(X_clean)\n",
    "\n",
    "Y_pred_chains2_new = np.array([chain.predict(X_new_tran) for chain in chains2])\n",
    "y_pred_new = stats.mode(Y_pred_chains2_new)[0]\n",
    "\n",
    "#predicted1 = OneVsRest_classifier.predict(X_new)\n",
    "\n",
    "#y_pred_new 维度不对，要取第一个元素\n",
    "output = mlb.inverse_transform(y_pred_new[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "asString = []\n",
    "for s in output:\n",
    "    st = str(s).replace('(', '').replace(')', '').replace(\"'\", '')\n",
    "    #print(len(st))\n",
    "    if len(st) != 0 and st[-1] == ',':\n",
    "        st = st[:-1]\n",
    "    asString.append(st)\n",
    "    \n",
    "new_data['Project Tag Original'] = asString\n",
    "\n",
    "#new_data['Project Tag Summarized'] = asString\n",
    "#将predict得到的结果放到csv里面\n",
    "new_data.to_csv(\"final data.csv\", sep = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['General Public', 'Legislators', 'N/A', 'Primary School Students',\n",
       "       'Professors', 'Scientific Community', 'Secondary School Students',\n",
       "       'Specialized Audience', 'Teachers', 'University Students',\n",
       "       'Vendors/Businesses', 'iGEM Teams'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y1 = data['Audience']\n",
    "mlb = MultiLabelBinarizer()\n",
    "y1 = y1.fillna(\"N/A\")\n",
    "y1 = y1.str.split(', ')\n",
    "\n",
    "for i in range(0, len(y1)):\n",
    "    for j in range(0, len(y1[i])):\n",
    "        y1[i][j] = y1[i][j].replace('General Public ','General Public')\\\n",
    "        .replace('Primary School Students ','Primary School Students')\\\n",
    "        .replace('Primary School Students  ','Primary School Students')\\\n",
    "        .replace('Primary School Students   ','Primary School Students')\\\n",
    "        .replace('Scientific Community ', 'Scientific Community')\\\n",
    "        .replace('Specialized Audience ', 'Specialized Audience')\\\n",
    "        .replace('Specialized Audiences', 'Specialized Audience')\\\n",
    "        .replace('Vendors/Businesses ', 'Vendors/Businesses')\\\n",
    "        .replace('iGEM Teams ', 'iGEM Teams')\n",
    "\n",
    "mlb_y1 = mlb.fit_transform(y1)\n",
    "mlb.classes_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#multilabel classifier: Audience 0.9324839247439867\n",
    "\n",
    "\n",
    "#from sklearn.model_selection import train_test_split\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, mlb_y1, test_size=0.3, random_state=52)\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.multioutput import ClassifierChain\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Fit an ensemble of SVM classifier chains and take the average prediction of all the chains.\n",
    "from sklearn.metrics import jaccard_score\n",
    "chains1 = [ClassifierChain(SVC(C=1.0, kernel='linear'), order='random', random_state=i)\n",
    "          for i in range(10)]\n",
    "for chain in chains1:\n",
    "    #chain.fit(X_train, y_train)\n",
    "    chain.fit(X_tran, mlb_y1)\n",
    "    \n",
    "#Y_pred_chains = np.array([chain.predict(X_test) for chain in chains])\n",
    "\n",
    "\n",
    "#0项是mode，1项是count\n",
    "#y_pred = stats.mode(Y_pred_chains)[0]\n",
    "\n",
    "\n",
    "#simple match\n",
    "#print('Chain_Classifier_test:'+ str(np.mean(y_pred == y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred_chains1_new = np.array([chain.predict(X_new_tran) for chain in chains1])\n",
    "y_pred_new = stats.mode(Y_pred_chains1_new)[0]\n",
    "\n",
    "#y_pred_new 维度不对，要取第一个元素\n",
    "output1 = mlb.inverse_transform(y_pred_new[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "asString = []\n",
    "for s in output1:\n",
    "    st = str(s).replace('(', '').replace(')', '').replace(\"'\", '')\n",
    "    #print(len(st))\n",
    "    if len(st) != 0 and st[-1] == ',':\n",
    "        st = st[:-1]\n",
    "    asString.append(st)\n",
    "    \n",
    "new_data['Audience Original'] = asString\n",
    "\n",
    "#new_data['Audience Summarized'] = asString\n",
    "#将predict得到的结果放到csv里面\n",
    "new_data.to_csv(\"final data.csv\", sep = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Activism for iGEM Project', 'Activism for iGEM project',\n",
       "       'Discuss Ethics and Safety', 'Education on Synthetic Biology',\n",
       "       'Education on iGEM Program', 'Gain Information for iGEM Project',\n",
       "       'Learn Public Opinion', 'N/A', 'Networking', 'Policy Outreach',\n",
       "       'Present iGEM Project', 'Promote Awareness of Synthetic Biology',\n",
       "       'Recruit iGEM Members', 'Science Education',\n",
       "       'Science Education(Non-SynBio Specific)'], dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y3 = data['Goal']\n",
    "mlb = MultiLabelBinarizer()\n",
    "y3 = y3.fillna(\"N/A\")\n",
    "y3 = y3.str.split(', ')\n",
    "for i in range(0, len(y3)):\n",
    "    for j in range(0, len(y3[i])):\n",
    "        y3[i][j] = y3[i][j].replace(' Educate on Synthetic Biology','Education on Synthetic Biology')\\\n",
    "        .replace('Educate on Synthetic Biology','Education on Synthetic Biology')\\\n",
    "        .replace('Education on Synthetic Biology ','Education on Synthetic Biology')\\\n",
    "        .replace(' Promote Awareness of Synthetic Biology','Promote Awareness of Synthetic Biology')\\\n",
    "        .replace('Promote Awareness of Synthetic Biology ','Promote Awareness of Synthetic Biology')\\\n",
    "        .replace('Discuss Ethics and Safety ','Discuss Ethics and Safety')\\\n",
    "        .replace('Gain Information for iGEM Project ','Gain Information for iGEM Project')\\\n",
    "        .replace('Educate on the iGEM program', 'Education on iGEM Program')\\\n",
    "        .replace('Educate on iGEM Program', 'Education on iGEM Program')\\\n",
    "        .replace('Gain Information for iGEM project',  'Gain Information for iGEM Project')\\\n",
    "        .replace('Learn Public Opinions', 'Learn Public Opinion')\\\n",
    "        .replace('Networking ', 'Networking')\\\n",
    "        .replace('Present iGEM Project ', 'Present iGEM Project')\\\n",
    "        .replace('Promote Awareness of Synthetic Biology ', 'Promote Awareness of Synthetic Biology')\\\n",
    "        .replace('Recruit iGEM Members ', 'Recruit iGEM Members')\\\n",
    "        .replace('Recruit iGEM members', 'Recruit iGEM Members')\\\n",
    "        .replace('Science Education ', 'Science Education')\n",
    "mlb_y3 = mlb.fit_transform(y3)\n",
    "mlb.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#multilabel classifier: Goal 0.9207430340557275\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.multioutput import ClassifierChain\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Fit an ensemble of SVM classifier chains and take the average prediction of all the chains.\n",
    "from sklearn.metrics import jaccard_score\n",
    "chains3 = [ClassifierChain(SVC(C=1.0, kernel='linear'), order='random', random_state=i)\n",
    "          for i in range(10)]\n",
    "for chain in chains3:\n",
    "    chain.fit(X_tran, mlb_y3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred_chains3_new = np.array([chain.predict(X_new_tran) for chain in chains3])\n",
    "y_pred3_new = stats.mode(Y_pred_chains3_new)[0]\n",
    "\n",
    "#y_pred_new 维度不对，要取第一个元素\n",
    "output3 = mlb.inverse_transform(y_pred3_new[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "asString = []\n",
    "for s in output3:\n",
    "    st = str(s).replace('(', '').replace(')', '').replace(\"'\", '')\n",
    "    #print(len(st))\n",
    "    if len(st) != 0 and st[-1] == ',':\n",
    "        st = st[:-1]\n",
    "    asString.append(st)\n",
    "    \n",
    "new_data['Goal Original'] = asString\n",
    "\n",
    "#new_data['Goal Summarized'] = asString\n",
    "#将predict得到的结果放到csv里面\n",
    "new_data.to_csv(\"final data.csv\", sep = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

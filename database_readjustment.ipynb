{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import re\n",
    "data = pd.read_csv('edited_data.csv')\n",
    "X = data['Objectives']+'. '+ data['Description']\n",
    "\n",
    "X = X.str.replace('<ul>', '').str.replace('<li>','').str.replace('</li>','').str.replace('</ul>','').str.replace('\\n','')\n",
    "\n",
    "X = X.fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       contribution metu hs ankara lab protocols coll...\n",
      "1       attend makerfaire hannover demonstrate first p...\n",
      "2       organize biotech day present project large gro...\n",
      "3       contact connect community labs europe visit ig...\n",
      "4       invite technik garage german community lab aac...\n",
      "                              ...                        \n",
      "2148                                                     \n",
      "2149     attended fourth conference china igemer commu...\n",
      "2150     created week long exhibition three igem teams...\n",
      "2151     host architects competition microorganism app...\n",
      "2152     secure funding supplies metagenomic sequencin...\n",
      "Length: 2153, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords \n",
    "#nltk.download('punkt')\n",
    "#nltk.download(\"stopwords\")\n",
    "data = data.reset_index(drop=True)\n",
    "REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|@,;]')\n",
    "BAD_SYMBOLS_RE = re.compile('[^0-9a-z #+_]')\n",
    "stop_words = set(stopwords.words('english')) \n",
    "not_delete = [\"but\", \"shan't\", \"wasn't\", \"couldn't\", \"didn't\", \"hadn't\", \"against\", \"no\", \"haven't\", \"shouldn't\", \"needn't\", \"wouldn't\", \"aren't\", \"mightn't\", \"won't\", \"isn't\", \"hasn't\", \"don't\", \"mustn't\", \"doesn't\", \"not\"]\n",
    "STOPWORDS = [w for w in stop_words if w not in not_delete]\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "        text: a string\n",
    "        \n",
    "        return: modified initial string\n",
    "    \"\"\"\n",
    "    text = text.lower() # lowercase text\n",
    "    text = REPLACE_BY_SPACE_RE.sub(' ', text) # replace REPLACE_BY_SPACE_RE symbols by space in text. substitute the matched string in REPLACE_BY_SPACE_RE with space.\n",
    "    text = BAD_SYMBOLS_RE.sub('', text) # remove symbols which are in BAD_SYMBOLS_RE from text. substitute the matched string in BAD_SYMBOLS_RE with nothing. \n",
    "    text = ' '.join(word for word in text.split() if word not in STOPWORDS) # remove stopwors from text\n",
    "    return text\n",
    "\n",
    "X = X.apply(clean_text)\n",
    "X = X.str.replace('\\d+', '')\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "porter = PorterStemmer()\n",
    "def stemSentence(sentence):\n",
    "    token_words=word_tokenize(sentence)\n",
    "    stem_sentence=[]\n",
    "    for word in token_words:\n",
    "        stem_sentence.append(porter.stem(word))\n",
    "        stem_sentence.append(\" \")\n",
    "    return \"\".join(stem_sentence)\n",
    "\n",
    "for i in range(0,X.count()):\n",
    "    X[i] = stemSentence(X[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "print(type(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#multilabel classifier: project tag %95\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from scipy import stats\n",
    "\n",
    "y2 = data['Project Tag']\n",
    "mlb = MultiLabelBinarizer()\n",
    "y2 = y2.fillna(\"N/A\")\n",
    "y2 = y2.str.split(', ')\n",
    "\n",
    "for i in range(0, len(y2)):\n",
    "    for j in range(0, len(y2[i])):\n",
    "        y2[i][j] = y2[i][j].replace(\"Community Event \", \"Community Event\")\\\n",
    "        .replace(\"Conference/Panel Discussion \", \"Conference/Panel Discussion\")\\\n",
    "        .replace(\"Educational Material \", \"Educational Material\")\\\n",
    "        .replace(\"Social Media \", \"Social Media\").replace(\"Survey \", \"Survey\")\\\n",
    "        .replace(\"Teaching Activity \", \"Teaching Activity\")\n",
    "    \n",
    "mlb_y2 = mlb.fit_transform(y2)\n",
    "\n",
    "#print(mlb.classes_)\n",
    "\n",
    "#from sklearn.model_selection import train_test_split\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, mlb_y2, test_size=0.3, random_state=52)\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.multioutput import ClassifierChain\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "'''\n",
    "#Bag of Words\n",
    "OneVsRest_classifier = Pipeline([\n",
    "('vectorizer', CountVectorizer(ngram_range=(1, 2),strip_accents = 'unicode')),\n",
    "('tfidf', TfidfTransformer(sublinear_tf=True)),\n",
    "('clf', OneVsRestClassifier(SVC(C=1.0, kernel='linear')))])\n",
    "\n",
    "OneVsRest_classifier.fit(X_train, y_train) \n",
    "predicted = OneVsRest_classifier.predict(X_test)\n",
    "\n",
    "\n",
    "#exact match\n",
    "print(OneVsRest_classifier.score(X_test, y_test))\n",
    "\n",
    "#simple match\n",
    "print('OneVsRestClassifier_test:'+ str(np.mean(predicted == y_test)))\n",
    "'''\n",
    "\n",
    "Tfidf_vect = TfidfVectorizer(ngram_range=(1, 2), strip_accents = 'unicode')\n",
    "#X_train = Tfidf_vect.fit_transform(X_train)\n",
    "#X_test = Tfidf_vect.transform(X_test)\n",
    "X_tran = Tfidf_vect.fit_transform(X)\n",
    "\n",
    "# Fit an ensemble of SVM classifier chains and take the average prediction of all the chains.\n",
    "from sklearn.metrics import jaccard_score\n",
    "chains = [ClassifierChain(SVC(C=1.0, kernel='linear'), order='random', random_state=i)\n",
    "          for i in range(10)]\n",
    "for chain in chains:\n",
    "    #chain.fit(X_train, y_train)\n",
    "    chain.fit(X_tran, mlb_y2)\n",
    "    \n",
    "#Y_pred_chains = np.array([chain.predict(X_test) for chain in chains])\n",
    "\n",
    "\n",
    "#0项是mode，1项是count\n",
    "#y_pred = stats.mode(Y_pred_chains)[0]\n",
    "\n",
    "\n",
    "#simple match\n",
    "#print('Chain_Classifier_test:'+ str(np.mean(y_pred == y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected indicator for 17 classes, but got 1096",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-2d954dce5806>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m#predicted1 = OneVsRest_classifier.predict(X_new)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmlb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred_new\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/label.py\u001b[0m in \u001b[0;36minverse_transform\u001b[0;34m(self, yt)\u001b[0m\n\u001b[1;32m    973\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0myt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    974\u001b[0m             raise ValueError('Expected indicator for {0} classes, but got {1}'\n\u001b[0;32m--> 975\u001b[0;31m                              .format(len(self.classes_), yt.shape[1]))\n\u001b[0m\u001b[1;32m    976\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    977\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0missparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Expected indicator for 17 classes, but got 1096"
     ]
    }
   ],
   "source": [
    "#OneVsRest_classifier.fit(X, mlb_y2)\n",
    "new_data = pd.read_csv('initial_data.csv')\n",
    "X_new = new_data['Descriptions']\n",
    "X_new = X_new.str.replace('\\n', '').str.replace('\\t','')\n",
    "X_new = X_new.fillna('')\n",
    "\n",
    "X_new_tran = Tfidf_vect.transform(X_new)\n",
    "\n",
    "Y_pred_chains_new = np.array([chain.predict(X_new_tran) for chain in chains])\n",
    "y_pred_new = stats.mode(Y_pred_chains_new)[0]\n",
    "\n",
    "#predicted1 = OneVsRest_classifier.predict(X_new)\n",
    "\n",
    "output = mlb.inverse_transform(y_pred_new[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = mlb.inverse_transform(y_pred_new[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
